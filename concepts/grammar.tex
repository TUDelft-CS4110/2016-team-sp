\textbf{The summary beneath is completely created from \cite{godefroid2008grammar}}
\\

Blackbox fuzzing is a form of testing, heavily used for finding security vulnerabilities in software. 
Blackbox fuzzing sometimes uses grammars to generate the well-formed inputs, as well as to encode application=specific knowledge and test heuristics for guiding the generation of input variants.
Whitebox fuzzing combines fuzz testing with dynamic test generation.
Whitebox fuzzing executes the program under test with an initial, well-formed input, both concretely and symbolically.

Unfortunately, the current effectiveness of whitebox fuzzing is limited when testing applications with highly-structured inputs.
\textit{Grammar-based whitebox fuzzing} enhances whitebox fuzzing with a grammar-based specification of valid inputs. A dunamix test generation algorithm is presented, where symbolic execution directly generates grammar-based constraints whose satisfiability is checked using a custom grammar-based constraint solver.
The algorithm has two key components:
\begin{itemize}
    \item Generation of higher-level symbolic constraints, expressed in terms of symbolic grammar tokens returned by the lexer, instead of the traditional symbolic bytes read as input.
    \item A custom constraint solver that solves constraints on symbolic grammar tokens. The solver looks for solutions that satisfy the constraints and are accepted by a given (context-free) grammar.
\end{itemize}

Results of experiments show that grammar-based whitebox fuzzing outperforms whitebox fuzzing, blackbox fuzzing and grammar-based blackbox fuzzing in overall code coverage, while using fewer tests.

Grammar-based whitebox fuzzing prunes in one iteration the entire subtree of lexer executions corresponding to all possible non-parsable inputs.
Given a sequential deterministic program $P$ under test and an initial program input $I$, this dynamic test generation algorithm generates new test inputs by negating constraints generated during the symbolic execution of program $P$ with input $I$. These new inputs exercise different execution paths in $P$. This process is repeated and the algorithm executes the program with new inputs multiple times - each newly generated input may lead to the generation of additional inputs. The algorithm terminates when a testing time budget expires or no more inputs can be generated.

Dynamic execution allows any imprecision in symbolic execution to be alleviated using concrete values and randomization: whenever symbolic execution does not know how to generate a constraint for a program statement depending on some inputs, one can always simplify this constraint using the concrete values of those inputs.

Grammar-based whitebox fuzzing is an extension of the algorithm described above:
\begin{itemize}
    \item The new algorithm requires a grammar $G$ that describes valid program inputs.
    \item Instead of marking the bytes in program inputs as symbolic, grammar-based whitebox fuzzing marks tokens returned from a tokenization function as symbolic; thus grammar-based whitebox associates a symbolic variable with each token, and symbolic execution tracks the influence of the tokens on the control path taken by the program $P$.
    \item The algorithm uses the grammar $G$ to require that new input not only satisfies the alternative path constraint but is also in the language accepted by the grammar.
    This additional requirement gives two advatages to grammar-based whitebox fuzzing: it allows pruning of the search tree corresponding to invalid inputs, and it allows the direct completion of satisfiable token constraints into valid inputs.
\end{itemize}

The constraint solver computes language intersection: it checks whether the language $L(pc)$ of inputs satisying the path constraint $pc$ contains an input that is in the language accepted by the grammar $G$.
A \textit{context-free constraint solver} takes as inputs a context-free grammar $G$ and a regular expression $R$, and returns either a string $s \in L(G) \bigcap L(R)$, or $\perp$ if the intersection is empty.

Some limitations and advantages of grammar-based whitebox fuzzing:
\textit{Computing language intersection} - Computing the intersection of a context-free grammar with a regular expression is a well-known problem.
\textit{Approcimate grammars} - Grammar-based whitebox fuzzing can be used with approximate grammars.
\textit{Domain knowledge} - Grammar-based whitebox fuzzing requires a limited amount of domain knowledge, namely the formal grammar, identifying the tokenization function to be instrumented, and providing a de-tokenization function to generate input byte strings from input token strings generated by a context-free constraint solver.
\textit{Lexer and parser bugs} - Using a grammar to filter out invalid inputs may reduce code coverage in the lexer and parser themselves, since the grammar explicitly prevents the execution of code paths handling invalid inputs in those stages.

Among all the automated test generation strategies considered, grammar-based whitebox achieves the best total coverage as well as the best coverage in the deepest examined module, the code generator.
It achieves results that are closest to the manual test suite, which predictably provides best coverage. The manual suite is diverse and extensive, but was developed with the cost of many man-months of work. In contrast, grammar-based whitebox requires minimal human effort, and quickly generates relatively good test inputs.
Also the following was observed:
\begin{itemize}
    \item \textit{Grammar-based whitebox fuzzing} achieves much better coverage than regular whitebox fuzzing.
    \item Grammar-based whitebox fuzzing performs also significantly better than grammar-based blackbox.
    \item Grammar-based whitebox fuzzing achieves the highest coverage using the fewest inputs, which means that this strategy generates inputs of higher quality.
    \item The blackbox and whitebox strategies achieved similar results in all categories.
    \item Reachability results show tha talmost all tested inputs reach the lexer. The results show that grammar-based whitebox has the highest percentage of deep-reaching inputs.
\end{itemize}

The results of the experiments validate the claim that grammar-based whitebox fuzzing is effective in reaching deeper into the tested application and exercising the code more thoroughly than other automated test generation strategies.
Grammar-based whitebox fuzzing tightly integrates constraint-based whitebox testing with grammar-based blackbox testing, and leverages the strengths of both.
Since grammars are bound to be partial specifications of valid inputs, grammar-based blackbox approaches are fundamentally limited. Thanks to whitebox dynamic test generation, some of this incompleteness can be recovered, which explains why grammar-based whitebox fuzzing also outperforms grammar-based blackbox fuzzing in the experiments.